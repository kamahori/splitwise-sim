_target_: model.ExpertArchitecture
name: mixtral-8x7b-expert
num_layers: 32
hidden_size: 14336
num_experts: 8
top_k_experts: 2
